{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import process_data\n",
    "# from data_objects.utterance import Utterance\n",
    "import os, yaml, sys, random, torchaudio\n",
    "import pyworld as pw\n",
    "import soundfile as sf\n",
    "sys.path.insert(1, '/homes/bdoc3/my_utils')\n",
    "from audio.worldvocoder import code_harmonic, sp_to_mfsc\n",
    "from my_os import recursive_file_retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, librosa, warnings, pdb\n",
    "\n",
    "# UTTERANCE CLASS\n",
    "\n",
    "class Utterance:\n",
    "    def __init__(self, frames_fpath, wave_fpath, config, feat_params):\n",
    "        self.frames_fpath = frames_fpath\n",
    "        self.wave_fpath = wave_fpath\n",
    "        self.config = config\n",
    "        self.feat_params = feat_params\n",
    "\n",
    "    def get_chunk(self, frames, n_frames, start=None):\n",
    "\n",
    "        if frames.shape[0] > n_frames:\n",
    "            if start == None:\n",
    "                start = np.random.randint(0, frames.shape[0] - n_frames)\n",
    "        else:\n",
    "#             print(f'frames.shape[0] {frames.shape[0]}, n_frames {n_frames}')\n",
    "            start = 0\n",
    "            pad_size = math.ceil(n_frames - frames.shape[0]/2)\n",
    "            if frames.ndim == 1:\n",
    "                pad_vec = np.full((pad_size), np.min(frames))\n",
    "            else:\n",
    "                pad_vec = np.full((pad_size, frames.shape[1]), np.min(frames))\n",
    "            frames = np.concatenate((pad_vec, frames, pad_vec))\n",
    "            \n",
    "        end = start + n_frames\n",
    "        print('start', start)\n",
    "        return frames[start:end], (start, end)\n",
    "\n",
    "# get features, either from audio or precomputed npy arrays.\n",
    "    def get_frames(self, n_frames, start=None):\n",
    "\n",
    "        if self.config.use_audio:\n",
    "            y, _ = sf.read(self.frames_fpath)\n",
    "            samps_per_frame = (self.feat_params['frame_dur_ms']/1000) * self.feat_params['sr']\n",
    "            required_size =  int(samps_per_frame * n_frames)\n",
    "            if y.shape[0] < 1:\n",
    "                # '+2' at end is for f0_estimation vector\n",
    "                frames = np.zeros((n_frames, (self.feat_params['num_feats']+self.feat_params['num_aper_feats']+2)))\n",
    "                start_end = (0, required_size)\n",
    "            else:\n",
    "                counter = 0\n",
    "                looper = True\n",
    "                while looper:\n",
    "                    if counter > 10:\n",
    "                        raise Exception(f'Could not find vocal segments after randomly selecting 10 segments of length {n_frames}.')\n",
    "                    try:\n",
    "                        if start == None:\n",
    "                            y_chunk, start_end = self.get_chunk(y, required_size)\n",
    "                        else:\n",
    "                            y_chunk, start_end = self.get_chunk(y, required_size, start)\n",
    "                        frames = process_data(y_chunk.astype('double'), self.feat_params, self.config)\n",
    "                        looper = False\n",
    "                    except ValueError as e:\n",
    "                        print(f'ValueError: {e}. Trying another random chunk from uttr: {self.frames_fpath}')\n",
    "                        counter +=1\n",
    "\n",
    "        else:\n",
    "            frames = np.load(self.frames_fpath)\n",
    "            frames, start_end = self.get_chunk(frames, n_frames)\n",
    "        # print('another utterance processed')\n",
    "        return frames[:n_frames], start_end\n",
    "\n",
    "    def random_partial(self, n_frames, num_feats):\n",
    "        \"\"\"\n",
    "        Crops the frames into a partial utterance of n_frames\n",
    "        \n",
    "        :param n_frames: The number of frames of the partial utterance\n",
    "        :return: the partial utterance frames and a tuple indicating the start and end of the \n",
    "        partial utterance in the complete utterance.\n",
    "        \"\"\"\n",
    "        # pdb.set_trace()\n",
    "\n",
    "        frames, start_end = self.get_frames(n_frames)\n",
    "        frames = frames[:,:num_feats]\n",
    "\n",
    "        # frames = (frames - frames.mean()) / frames.std() # normalise from 0-1 across entire numpy\n",
    "        # frames = (frames - frames.mean(axis=0)) / frames.std(axis=0) # normalise from 0-1 across features\n",
    "        # pdb.set_trace()   \n",
    "        return frames, start_end\n",
    "\n",
    "    def specific_partial(self, n_frames, num_feats, start):\n",
    "        \"\"\"\n",
    "        Crops the frames into a partial utterance of n_frames\n",
    "        \n",
    "        :param n_frames: The number of frames of the partial utterance\n",
    "        :return: the partial utterance frames and a tuple indicating the start and end of the \n",
    "        partial utterance in the complete utterance.\n",
    "        \"\"\"\n",
    "        # pdb.set_trace()\n",
    "\n",
    "        frames, start_end = self.get_frames(n_frames, start)\n",
    "        frames = frames[:,:num_feats]\n",
    "\n",
    "        # frames = (frames - frames.mean()) / frames.std() # normalise from 0-1 across entire numpy\n",
    "        # frames = (frames - frames.mean(axis=0)) / frames.std(axis=0) # normalise from 0-1 across features\n",
    "        # pdb.set_trace()   \n",
    "        return frames, start_end \n",
    "\n",
    "def process_data(y, feat_params, config):\n",
    "\n",
    "    if config.use_wav2world:\n",
    "        feats=pw.wav2world(y, feat_params['sr'],frame_period=feat_params['frame_dur_ms'])\n",
    "        harm = feats[1]\n",
    "        aper = feats[2]\n",
    "        refined_f0 = feats[0]\n",
    "    else:\n",
    "        if config.f0_extract == 'harvest':\n",
    "            f0, t_stamp = pw.harvest(y, feat_params['sr'], feat_params['fmin'], feat_params['fmax'], feat_params['frame_dur_ms'])\n",
    "        elif config.f0_extract =='dio':\n",
    "            f0, t_stamp = pw.dio(y, feat_params['sr'], feat_params['fmin'], feat_params['fmax'], frame_period = feat_params['frame_dur_ms'])\n",
    "        refined_f0 = pw.stonemask(y, f0, t_stamp, feat_params['sr'])\n",
    "        harm = pw.cheaptrick(y, refined_f0, t_stamp, feat_params['sr'], f0_floor=feat_params['fmin'])\n",
    "        aper = pw.d4c(y, refined_f0, t_stamp, feat_params['sr'])\n",
    "#     pdb.set_trace()\n",
    "    refined_f0 = freq_to_vuv_midi(refined_f0) # <<< this can be done at training time\n",
    "\n",
    "    # print('basic harm/aper/f0 features extracted')\n",
    "\n",
    "    if config.dim_red_method == 'code-h':\n",
    "        harm = code_harmonic(harm, feat_params['num_feats'])\n",
    "        aper = code_harmonic(aper, feat_params['num_aper_feats'])\n",
    "    elif config.dim_red_method == 'world':\n",
    "        harm = pw.code_spectral_envelope(harm, feat_params['sr'], feat_params['num_feats'])\n",
    "        aper = pw.code_aperiodicity(aper, feat_params['num_feats'])\n",
    "    elif config.dim_red_method == 'chandna':\n",
    "        harm = 10*np.log10(harm) # previously, using these logs was a separate optional process to 'chandna'\n",
    "        aper = 10*np.log10(aper**2)\n",
    "        harm = sp_to_mfsc(harm, feat_params['num_feats'], 0.45)\n",
    "        aper =sp_to_mfsc(aper, 4, 0.45)\n",
    "    else:\n",
    "        raise Exception(\"The value for dim_red_method was not recognised\")\n",
    "    # print(f'{random.randint(0,100)}feature dims reduced')\n",
    "\n",
    "\n",
    "    out_feats=np.concatenate((harm,aper,refined_f0),axis=1)\n",
    "\n",
    "    return out_feats\n",
    "\n",
    "\n",
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isinf(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "\n",
    "def freq_to_vuv_midi(f0):\n",
    "    \"Convert to midi notes, with second vector displaying 1 when there's no pitch detected\"\n",
    "    with warnings.catch_warnings(): # warning \n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        notes_y = 69+12*np.log2(f0/440)\n",
    "    y = notes_y\n",
    "    \"Nan related\"\n",
    "    nans, x= nan_helper(y)\n",
    "    if np.all(nans) == True:\n",
    "        raise ValueError('No voice pitch detected in segment')\n",
    "    naners=np.isinf(y)\n",
    "    y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    y=np.array(y).reshape([len(y),1])\n",
    "    guy=np.array(naners).reshape([len(y),1])\n",
    "    y=np.concatenate((y,guy),axis=-1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(data_path, 'feat_params.yaml'), 'rb') as Handle:\n",
    "#     feat_params = yaml.load(Handle, Loader=yaml.FullLoader)\n",
    "\n",
    "class Object():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1418829056_1704865349.wav, process 0\n",
      "start 57\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/1418829056/1418829056_1704865349.wav\n",
      "start 22105\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/1418829056/1418829056_1704865349.wav\n",
      "start 8250\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/1418829056/1418829056_1704865349.wav\n",
      "start 42645\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/1418829056/1418829056_1704865349.wav\n",
      "start 2578\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/1418829056/1418829056_1704865349.wav\n",
      "start 15605\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/1418829056/1418829056_1704865349.wav\n",
      "start 13334\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/1418829056/1418829056_1704865349.wav\n",
      "start 4526\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/1418829056/1418829056_1704865349.wav\n",
      "start 14312\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/1418829056/1418829056_1704865349.wav\n",
      "start 18993\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/1418829056/1418829056_1704865349.wav\n",
      "start 11372\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/1418829056/1418829056_1704865349.wav\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Could not find vocal segments after randomly selecting 10 segments of length 307.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_214617/2020724225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtterance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mu_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;31m#             u_part = u.specific_partial(n_frames, num_feats, 31000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0muttrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_part\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_214617/2776777371.py\u001b[0m in \u001b[0;36mrandom_partial\u001b[0;34m(self, n_frames, num_feats)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_feats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_214617/2776777371.py\u001b[0m in \u001b[0;36mget_frames\u001b[0;34m(self, n_frames, start)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mlooper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Could not find vocal segments after randomly selecting 10 segments of length {n_frames}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Could not find vocal segments after randomly selecting 10 segments of length 307."
     ]
    }
   ],
   "source": [
    "config = Object()\n",
    "config.use_audio = True\n",
    "config.use_wav2world = True\n",
    "config.f0_extract = 'harvest'\n",
    "config.dim_red_method = 'chandna'\n",
    "feat_params = {\"use_wav2world\":config.use_wav2world,\n",
    "                                \"f0_extract\":config.f0_extract,\n",
    "                                \"dim_red_method\":config.dim_red_method,\n",
    "                                \"fmin\":71,\n",
    "                                \"fmax\":800,\n",
    "                                'num_feats':40,\n",
    "                                'num_aper_feats':4,\n",
    "                                'frame_dur_ms':5,\n",
    "                                'sr':16000,\n",
    "                                'fft_size':None}\n",
    "n_frames = 307\n",
    "num_feats = 40\n",
    "\n",
    "data_path = '/homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP'\n",
    "\n",
    "# issue_singers = ['1468732648'] #\n",
    "# issue_singers = ['1006811699'] # \n",
    "# issue_singers = ['424702701'] # there is no audio data saved for this singer\n",
    "issue_singers = ['1418829056']\n",
    "\n",
    "uttrs = []\n",
    "counter = 0\n",
    "while counter<3:\n",
    "    for i in issue_singers:\n",
    "        dir_path = os.path.join(data_path, 'train', i)\n",
    "        if not os.path.exists(dir_path):\n",
    "            dir_path = os.path.join(data_path, 'val', i)\n",
    "        _, _, files = next(os.walk(dir_path))\n",
    "        for file_name in files:\n",
    "            print(f'Processing {file_name}, process {counter}')\n",
    "            file_path = os.path.join(dir_path, file_name)\n",
    "            u = Utterance(file_path, file_path, config, feat_params)\n",
    "            u_part = u.random_partial(n_frames, num_feats)\n",
    "#             u_part = u.specific_partial(n_frames, num_feats, 31000)\n",
    "            uttrs.append(u_part)\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use original dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /import/c4dm-datasets/DAMP_Intonation_Dataset/vocal_tracks/1418829056_1704865349.m4a, process 0\n",
      "start 2795860\n",
      "Processing /import/c4dm-datasets/DAMP_Intonation_Dataset/vocal_tracks/1418829056_1704865349.m4a, process 1\n",
      "start 4688143\n",
      "Processing /import/c4dm-datasets/DAMP_Intonation_Dataset/vocal_tracks/1418829056_1704865349.m4a, process 2\n",
      "start 5744079\n"
     ]
    }
   ],
   "source": [
    "data_path = '/import/c4dm-datasets/DAMP_Intonation_Dataset/vocal_tracks'\n",
    "_, all_fps = recursive_file_retrieval(data_path)\n",
    "\n",
    "# issue_singers = ['1468732648'] #\n",
    "# issue_singers = ['1006811699'] # \n",
    "# issue_singers = ['424702701'] # there is no audio data saved for this singer\n",
    "s_id = '1418829056'\n",
    "\n",
    "\n",
    "\n",
    "uttrs = []\n",
    "counter = 0\n",
    "for fp in all_fps:\n",
    "    if s_id in fp:\n",
    "        while counter <3:\n",
    "            print(f'Processing {fp}, process {counter}')\n",
    "            u = Utterance(fp, fp, config, feat_params)\n",
    "            u_part = u.random_partial(n_frames, num_feats)\n",
    "    #             u_part = u.specific_partial(n_frames, num_feats, 31000)\n",
    "            uttrs.append(u_part)\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeit experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP'\n",
    "\n",
    "# all_dirs, files = recursive_file_retrieval(data_path)\n",
    "# wav_files = [f for f in files if f.endswith('wav')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/import/c4dm-datasets/DAMP_Intonation_Dataset/vocal_tracks'\n",
    "\n",
    "all_dirs, files = recursive_file_retrieval(data_path)\n",
    "wav_files = [f for f in files if f.endswith('m4a')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeit results for loading files only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit librosa.load(wav_files[random.randint(0, len(wav_files))]) #  1.57 s ± 631 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# %timeit sf.read(wav_files[random.randint(0, len(wav_files))]) #53.8 ms ± 16.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "# %timeit torchaudio.load(wav_files[random.randint(0, len(wav_files))]) #44.2 ms ± 23.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeit results for loading and processing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 2364070\n",
      "start 4671904\n",
      "start 551183\n",
      "start 1747801\n",
      "ValueError: No voice pitch detected in segment. Trying another random chunk from uttr: /import/c4dm-datasets/DAMP_Intonation_Dataset/vocal_tracks/313835696_1839888461.m4a\n",
      "start 982368\n",
      "start 505968\n",
      "start 2330506\n",
      "start 5386925\n",
      "start 2066420\n",
      "367 ms ± 53.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# with librosa IO on wav - 1.98 s ± 220 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# with sf IO on wav - 264 ms ± 14.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# with sf IO on m4a - 367 ms ± 53.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "\n",
    "file_path = wav_files[random.randint(0, len(wav_files))]\n",
    "u = Utterance(file_path, file_path, config, feat_params)\n",
    "u_part = u.random_partial(n_frames, num_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 664268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ -5.53413142,  -5.16761401,  -6.13489713, ..., -23.56622401,\n",
       "         -24.75902111, -35.46205331],\n",
       "        [ -7.44956002,  -8.1365492 ,  -7.68187535, ..., -22.74666417,\n",
       "         -23.07679609, -32.91781073],\n",
       "        [ -7.82786729,  -8.06915859,  -7.88852626, ..., -24.24993222,\n",
       "         -24.08777826, -32.59682484],\n",
       "        ...,\n",
       "        [ -4.24098048,  -5.18928258,  -4.57552981, ..., -21.62389486,\n",
       "         -20.34128273, -28.53943275],\n",
       "        [ -4.33712282,  -5.15864007,  -4.64674877, ..., -21.21071475,\n",
       "         -19.01734806, -30.59034519],\n",
       "        [ -4.28971528,  -4.9698928 ,  -4.67096784, ..., -19.60396634,\n",
       "         -22.53332584, -33.21100276]]),\n",
       " (664268, 713388))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = wav_files[random.randint(0, len(wav_files))]\n",
    "file_path = '/homes/bdoc3/my_data/audio_data/deslienced_concat_DAMP/train/374399338/374399338_1741657119.wav'\n",
    "u = Utterance(file_path, file_path, config, feat_params)\n",
    "u.frames_fpath\n",
    "u.random_partial(307, 40)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f62c09e4756faa82e7be093ccf48d7a4ce580f4dbfadca0d80f9d90a0320dae2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
